{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT 模型训练.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNz+VeGtxsCiirxk1weiO9y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":976},"id":"y5Grot3bWBE4","executionInfo":{"status":"ok","timestamp":1648040904142,"user_tz":-480,"elapsed":21957,"user":{"displayName":"Yuxin Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15214000089252266369"}},"outputId":"a6d28fcd-cecd-4aca-fa17-15f18c5b7622"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: numpy 1.21.5\n","Uninstalling numpy-1.21.5:\n","  Would remove:\n","    /usr/bin/f2py\n","    /usr/local/bin/f2py\n","    /usr/local/bin/f2py3\n","    /usr/local/bin/f2py3.7\n","    /usr/local/lib/python3.7/dist-packages/numpy-1.21.5.dist-info/*\n","    /usr/local/lib/python3.7/dist-packages/numpy.libs/libgfortran-2e0d59d6.so.5.0.0\n","    /usr/local/lib/python3.7/dist-packages/numpy.libs/libopenblasp-r0-2d23e62b.3.17.so\n","    /usr/local/lib/python3.7/dist-packages/numpy.libs/libquadmath-2d0c479f.so.0.0.0\n","    /usr/local/lib/python3.7/dist-packages/numpy/*\n","Proceed (y/n)? y\n","  Successfully uninstalled numpy-1.21.5\n","Collecting numpy\n","  Downloading numpy-1.21.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n","\u001b[K     |████████████████████████████████| 15.7 MB 4.0 MB/s \n","\u001b[?25hInstalling collected packages: numpy\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed numpy-1.21.5\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting boto3\n","  Downloading boto3-1.21.24-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 4.3 MB/s \n","\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n","  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 9.4 MB/s \n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n","  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n","Collecting botocore<1.25.0,>=1.24.24\n","  Downloading botocore-1.24.24-py3-none-any.whl (8.6 MB)\n","\u001b[K     |████████████████████████████████| 8.6 MB 36.6 MB/s \n","\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n","  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 44.3 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.24->boto3) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.24->boto3) (1.15.0)\n","Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.9 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed boto3-1.21.24 botocore-1.24.24 jmespath-1.0.0 s3transfer-0.5.2 urllib3-1.26.9\n"]}],"source":["!pip uninstall numpy\n","!pip install -U numpy\n","!pip install boto3"]},{"cell_type":"code","source":["import sys\n","from google.colab import drive\n","drive.mount('/content/drive')\n","sys.path.append('/content/drive/MyDrive/Bert-Chinese-Text-Classification-Pytorch-master')\n","\n","sys.argv=['']\n","del sys"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_NUz08MIW_Nq","executionInfo":{"status":"ok","timestamp":1648040930753,"user_tz":-480,"elapsed":23288,"user":{"displayName":"Yuxin Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15214000089252266369"}},"outputId":"34992425-6941-463c-9ff8-3e3168f36199"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","f=open('/content/drive/MyDrive/Bert-Chinese-Text-Classification-Pytorch-master/THUCNews/data/all_data_with_label.txt','r',encoding='utf-8')\n","data=f.readlines()\n","f.close()"],"metadata":{"id":"W0nL4GER_CnB","executionInfo":{"status":"ok","timestamp":1648040938401,"user_tz":-480,"elapsed":1878,"user":{"displayName":"Yuxin Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15214000089252266369"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["train_set,test_set=train_test_split(data,test_size=0.4)\n","dev_set,test_set=train_test_split(test_set,test_size=0.4)"],"metadata":{"id":"vNXxMHn0AGVl","executionInfo":{"status":"ok","timestamp":1648040940210,"user_tz":-480,"elapsed":3,"user":{"displayName":"Yuxin Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15214000089252266369"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["f=open('/content/drive/MyDrive/Bert-Chinese-Text-Classification-Pytorch-master/THUCNews/data/train.txt','w',encoding='utf-8')\n","for i in train_set:\n","  f.write(i)\n","f.close()\n","\n","f=open('/content/drive/MyDrive/Bert-Chinese-Text-Classification-Pytorch-master/THUCNews/data/dev.txt','w',encoding='utf-8')\n","for i in dev_set:\n","  f.write(i)\n","f.close()\n","\n","f=open('/content/drive/MyDrive/Bert-Chinese-Text-Classification-Pytorch-master/THUCNews/data/test.txt','w',encoding='utf-8')\n","for i in test_set:\n","  f.write(i)\n","f.close()"],"metadata":{"id":"g1pQBcDmAKmG","executionInfo":{"status":"ok","timestamp":1648040942185,"user_tz":-480,"elapsed":2,"user":{"displayName":"Yuxin Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15214000089252266369"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# coding: UTF-8\n","import torch\n","import torch.nn as nn\n","# from pytorch_pretrained_bert import BertModel, BertTokenizer\n","from pytorch_pretrained import BertModel, BertTokenizer\n","\n","\n","class Config(object):\n","\n","    \"\"\"配置参数\"\"\"\n","    def __init__(self, dataset):\n","        self.model_name = 'bert'\n","        self.train_path = dataset + '/data/train.txt'                                # 训练集\n","        self.dev_path = dataset + '/data/dev.txt'                                    # 验证集\n","        self.test_path = dataset + '/data/test.txt'                                  # 测试集\n","        self.class_list = [x.strip() for x in open(\n","            dataset + '/data/class_my.txt').readlines()]                                # 类别名单\n","        self.save_path = dataset + '/saved_dict/' + self.model_name + '_without_my.ckpt'        # 模型训练结果\n","        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')   # 设备\n","\n","        self.require_improvement = 1000                                 # 若超过1000batch效果还没提升，则提前结束训练\n","        self.num_classes = len(self.class_list)                         # 类别数\n","        #self.num_epochs = 3                                             # epoch数\n","        self.num_epochs = 25\n","        #self.batch_size = 128\n","        self.batch_size = 8                                           # mini-batch大小\n","        self.pad_size = 32                                              # 每句话处理成的长度(短填长切)\n","        self.learning_rate = 5e-5                                       # 学习率\n","        self.bert_path = 'bert-base-chinese'\n","        self.tokenizer = BertTokenizer.from_pretrained(self.bert_path)\n","        self.hidden_size = 768\n","\n","\n","class Model(nn.Module):\n","\n","    def __init__(self, config):\n","        super(Model, self).__init__()\n","        self.bert = BertModel.from_pretrained(config.bert_path)\n","        for param in self.bert.parameters():\n","            param.requires_grad = True\n","        self.fc = nn.Linear(config.hidden_size, config.num_classes)\n","\n","    def forward(self, x):\n","        context = x[0]  # 输入的句子\n","        mask = x[2]  # 对padding部分进行mask，和句子一个size，padding部分用0表示，如：[1, 1, 1, 1, 0, 0]\n","        _, pooled = self.bert(context, attention_mask=mask, output_all_encoded_layers=False)\n","        out = self.fc(pooled)\n","        return out\n"],"metadata":{"id":"d5ut8GUzXVrm","executionInfo":{"status":"ok","timestamp":1648041191790,"user_tz":-480,"elapsed":567,"user":{"displayName":"Yuxin Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15214000089252266369"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# coding: UTF-8\n","import time\n","import torch\n","import numpy as np\n","from train_eval import train, init_network\n","import argparse\n","from utils import build_dataset, build_iterator, get_time_dif\n","\n","parser = argparse.ArgumentParser(description='Chinese Text Classification')\n","#parser.add_argument('--model', type=str, required=True, help='choose a model: Bert, ERNIE')\n","parser.add_argument('--model',default='bert',help='Bert')\n","args = parser.parse_args()\n","\n","\n","if __name__ == '__main__':\n","    dataset = '/content/drive/MyDrive/Bert-Chinese-Text-Classification-Pytorch-master/THUCNews'  # 数据集\n","\n","    model_name = args.model  # bert\n","    config = Config(dataset)\n","    np.random.seed(1)\n","    torch.manual_seed(1)\n","    torch.cuda.manual_seed_all(1)\n","    torch.backends.cudnn.deterministic = True  # 保证每次结果一样\n","\n","    start_time = time.time()\n","    print(\"Loading data...\")\n","    train_data, dev_data, test_data = build_dataset(config)\n","    train_iter = build_iterator(train_data, config)\n","    dev_iter = build_iterator(dev_data, config)\n","    test_iter = build_iterator(test_data, config)\n","    time_dif = get_time_dif(start_time)\n","    print(\"Time usage:\", time_dif)\n","\n","    # train\n","    model = Model(config).to(config.device)\n","    dev_log,train_log = train(config, model, train_iter, dev_iter, test_iter)"],"metadata":{"id":"fAekkF-CXldf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648041379283,"user_tz":-480,"elapsed":185778,"user":{"displayName":"Yuxin Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15214000089252266369"}},"outputId":"6b2ee1f9-6a65-40c0-f54d-b682fff75faa"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading data...\n"]},{"output_type":"stream","name":"stderr","text":["400it [00:00, 12840.16it/s]\n","160it [00:00, 9759.02it/s]\n","107it [00:00, 10716.87it/s]"]},{"output_type":"stream","name":"stdout","text":["Time usage: 0:00:00\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/25]\n","Iter:      0,  Train Loss:   1.5,  Train Acc: 25.00%,  Val Loss:   1.5,  Val Acc: 15.00%,  Time: 0:00:02 *\n","Iter:     10,  Train Loss:   1.1,  Train Acc: 62.50%,  Val Loss:  0.87,  Val Acc: 66.88%,  Time: 0:00:05 *\n","Iter:     20,  Train Loss:   1.2,  Train Acc: 50.00%,  Val Loss:  0.57,  Val Acc: 78.75%,  Time: 0:00:07 *\n","Iter:     30,  Train Loss:  0.39,  Train Acc: 87.50%,  Val Loss:  0.23,  Val Acc: 93.12%,  Time: 0:00:10 *\n","Iter:     40,  Train Loss:  0.52,  Train Acc: 75.00%,  Val Loss:  0.23,  Val Acc: 91.25%,  Time: 0:00:13 *\n","Epoch [2/25]\n","Iter:     50,  Train Loss:  0.26,  Train Acc: 75.00%,  Val Loss:  0.24,  Val Acc: 88.75%,  Time: 0:00:14 \n","Iter:     60,  Train Loss:  0.92,  Train Acc: 87.50%,  Val Loss:  0.23,  Val Acc: 91.25%,  Time: 0:00:15 \n","Iter:     70,  Train Loss:  0.63,  Train Acc: 75.00%,  Val Loss:  0.17,  Val Acc: 93.75%,  Time: 0:00:18 *\n","Iter:     80,  Train Loss:  0.39,  Train Acc: 87.50%,  Val Loss:  0.14,  Val Acc: 95.62%,  Time: 0:00:21 *\n","Iter:     90,  Train Loss:  0.17,  Train Acc: 87.50%,  Val Loss:  0.14,  Val Acc: 96.25%,  Time: 0:00:23 *\n","Epoch [3/25]\n","Iter:    100,  Train Loss:  0.35,  Train Acc: 87.50%,  Val Loss:  0.24,  Val Acc: 90.00%,  Time: 0:00:25 \n","Iter:    110,  Train Loss:   0.8,  Train Acc: 75.00%,  Val Loss:   0.2,  Val Acc: 92.50%,  Time: 0:00:26 \n","Iter:    120,  Train Loss:   0.9,  Train Acc: 62.50%,  Val Loss:  0.25,  Val Acc: 90.00%,  Time: 0:00:27 \n","Iter:    130,  Train Loss:  0.26,  Train Acc: 87.50%,  Val Loss: 0.092,  Val Acc: 95.62%,  Time: 0:00:30 *\n","Iter:    140,  Train Loss:  0.11,  Train Acc: 100.00%,  Val Loss:  0.13,  Val Acc: 96.25%,  Time: 0:00:31 \n","Epoch [4/25]\n","Iter:    150,  Train Loss: 0.065,  Train Acc: 100.00%,  Val Loss:  0.12,  Val Acc: 95.62%,  Time: 0:00:33 \n","Iter:    160,  Train Loss:  0.95,  Train Acc: 87.50%,  Val Loss:  0.32,  Val Acc: 91.88%,  Time: 0:00:34 \n","Iter:    170,  Train Loss: 0.068,  Train Acc: 100.00%,  Val Loss:   0.2,  Val Acc: 95.00%,  Time: 0:00:35 \n","Iter:    180,  Train Loss:  0.25,  Train Acc: 87.50%,  Val Loss:   0.3,  Val Acc: 91.88%,  Time: 0:00:36 \n","Iter:    190,  Train Loss: 0.025,  Train Acc: 100.00%,  Val Loss:  0.25,  Val Acc: 93.75%,  Time: 0:00:38 \n","Epoch [5/25]\n","Iter:    200,  Train Loss:  0.75,  Train Acc: 87.50%,  Val Loss:  0.34,  Val Acc: 93.75%,  Time: 0:00:39 \n","Iter:    210,  Train Loss:  0.32,  Train Acc: 87.50%,  Val Loss:  0.13,  Val Acc: 95.62%,  Time: 0:00:41 \n","Iter:    220,  Train Loss: 0.037,  Train Acc: 100.00%,  Val Loss:  0.21,  Val Acc: 94.38%,  Time: 0:00:42 \n","Iter:    230,  Train Loss:  0.17,  Train Acc: 87.50%,  Val Loss:  0.31,  Val Acc: 91.88%,  Time: 0:00:43 \n","Iter:    240,  Train Loss: 0.035,  Train Acc: 100.00%,  Val Loss:  0.21,  Val Acc: 94.38%,  Time: 0:00:45 \n","Epoch [6/25]\n","Iter:    250,  Train Loss:   0.6,  Train Acc: 87.50%,  Val Loss: 0.057,  Val Acc: 98.12%,  Time: 0:00:48 *\n","Iter:    260,  Train Loss: 0.0093,  Train Acc: 100.00%,  Val Loss:  0.19,  Val Acc: 95.00%,  Time: 0:00:49 \n","Iter:    270,  Train Loss:  0.44,  Train Acc: 87.50%,  Val Loss: 0.036,  Val Acc: 98.12%,  Time: 0:00:52 *\n","Iter:    280,  Train Loss: 0.089,  Train Acc: 100.00%,  Val Loss:  0.06,  Val Acc: 98.75%,  Time: 0:00:53 \n","Iter:    290,  Train Loss: 0.004,  Train Acc: 100.00%,  Val Loss: 0.026,  Val Acc: 98.75%,  Time: 0:00:56 *\n","Epoch [7/25]\n","Iter:    300,  Train Loss: 0.0039,  Train Acc: 100.00%,  Val Loss: 0.051,  Val Acc: 96.88%,  Time: 0:00:58 \n","Iter:    310,  Train Loss: 0.041,  Train Acc: 100.00%,  Val Loss:  0.12,  Val Acc: 95.00%,  Time: 0:00:59 \n","Iter:    320,  Train Loss: 0.054,  Train Acc: 100.00%,  Val Loss: 0.065,  Val Acc: 97.50%,  Time: 0:01:00 \n","Iter:    330,  Train Loss:  0.16,  Train Acc: 87.50%,  Val Loss: 0.019,  Val Acc: 98.75%,  Time: 0:01:03 *\n","Iter:    340,  Train Loss: 0.0037,  Train Acc: 100.00%,  Val Loss:  0.02,  Val Acc: 99.38%,  Time: 0:01:04 \n","Epoch [8/25]\n","Iter:    350,  Train Loss: 0.0028,  Train Acc: 100.00%,  Val Loss: 0.025,  Val Acc: 98.75%,  Time: 0:01:05 \n","Iter:    360,  Train Loss: 0.0025,  Train Acc: 100.00%,  Val Loss: 0.085,  Val Acc: 96.88%,  Time: 0:01:07 \n","Iter:    370,  Train Loss: 0.0061,  Train Acc: 100.00%,  Val Loss:  0.12,  Val Acc: 96.88%,  Time: 0:01:08 \n","Iter:    380,  Train Loss: 0.047,  Train Acc: 100.00%,  Val Loss:  0.15,  Val Acc: 96.25%,  Time: 0:01:09 \n","Iter:    390,  Train Loss: 0.002,  Train Acc: 100.00%,  Val Loss:  0.03,  Val Acc: 98.75%,  Time: 0:01:10 \n","Epoch [9/25]\n","Iter:    400,  Train Loss: 0.0089,  Train Acc: 100.00%,  Val Loss:  0.04,  Val Acc: 98.12%,  Time: 0:01:11 \n","Iter:    410,  Train Loss: 0.013,  Train Acc: 100.00%,  Val Loss: 0.041,  Val Acc: 97.50%,  Time: 0:01:13 \n","Iter:    420,  Train Loss: 0.0092,  Train Acc: 100.00%,  Val Loss:  0.05,  Val Acc: 98.12%,  Time: 0:01:14 \n","Iter:    430,  Train Loss:  0.02,  Train Acc: 100.00%,  Val Loss: 0.061,  Val Acc: 97.50%,  Time: 0:01:16 \n","Iter:    440,  Train Loss: 0.0029,  Train Acc: 100.00%,  Val Loss: 0.057,  Val Acc: 98.12%,  Time: 0:01:17 \n","Epoch [10/25]\n","Iter:    450,  Train Loss: 0.0022,  Train Acc: 100.00%,  Val Loss: 0.047,  Val Acc: 98.12%,  Time: 0:01:19 \n","Iter:    460,  Train Loss: 0.0024,  Train Acc: 100.00%,  Val Loss: 0.047,  Val Acc: 98.12%,  Time: 0:01:20 \n","Iter:    470,  Train Loss: 0.0023,  Train Acc: 100.00%,  Val Loss: 0.047,  Val Acc: 98.12%,  Time: 0:01:21 \n","Iter:    480,  Train Loss: 0.012,  Train Acc: 100.00%,  Val Loss: 0.057,  Val Acc: 98.12%,  Time: 0:01:22 \n","Iter:    490,  Train Loss: 0.0014,  Train Acc: 100.00%,  Val Loss: 0.055,  Val Acc: 98.75%,  Time: 0:01:24 \n","Epoch [11/25]\n","Iter:    500,  Train Loss: 0.0087,  Train Acc: 100.00%,  Val Loss: 0.046,  Val Acc: 98.75%,  Time: 0:01:25 \n","Iter:    510,  Train Loss: 0.0013,  Train Acc: 100.00%,  Val Loss: 0.043,  Val Acc: 98.75%,  Time: 0:01:27 \n","Iter:    520,  Train Loss: 0.0015,  Train Acc: 100.00%,  Val Loss: 0.042,  Val Acc: 98.75%,  Time: 0:01:28 \n","Iter:    530,  Train Loss: 0.014,  Train Acc: 100.00%,  Val Loss: 0.043,  Val Acc: 98.75%,  Time: 0:01:30 \n","Iter:    540,  Train Loss: 0.0011,  Train Acc: 100.00%,  Val Loss: 0.046,  Val Acc: 98.75%,  Time: 0:01:31 \n","Epoch [12/25]\n","Iter:    550,  Train Loss: 0.00081,  Train Acc: 100.00%,  Val Loss: 0.042,  Val Acc: 98.12%,  Time: 0:01:33 \n","Iter:    560,  Train Loss: 0.0011,  Train Acc: 100.00%,  Val Loss: 0.049,  Val Acc: 98.75%,  Time: 0:01:34 \n","Iter:    570,  Train Loss: 0.0016,  Train Acc: 100.00%,  Val Loss: 0.049,  Val Acc: 98.12%,  Time: 0:01:35 \n","Iter:    580,  Train Loss: 0.007,  Train Acc: 100.00%,  Val Loss: 0.052,  Val Acc: 98.12%,  Time: 0:01:36 \n","Iter:    590,  Train Loss: 0.0009,  Train Acc: 100.00%,  Val Loss: 0.057,  Val Acc: 98.12%,  Time: 0:01:38 \n","Epoch [13/25]\n","Iter:    600,  Train Loss: 0.00072,  Train Acc: 100.00%,  Val Loss: 0.053,  Val Acc: 98.12%,  Time: 0:01:39 \n","Iter:    610,  Train Loss: 0.00091,  Train Acc: 100.00%,  Val Loss:  0.06,  Val Acc: 97.50%,  Time: 0:01:40 \n","Iter:    620,  Train Loss: 0.00098,  Train Acc: 100.00%,  Val Loss:  0.06,  Val Acc: 98.12%,  Time: 0:01:41 \n","Iter:    630,  Train Loss: 0.0034,  Train Acc: 100.00%,  Val Loss:  0.06,  Val Acc: 98.12%,  Time: 0:01:43 \n","Iter:    640,  Train Loss: 0.00083,  Train Acc: 100.00%,  Val Loss: 0.062,  Val Acc: 98.12%,  Time: 0:01:44 \n","Epoch [14/25]\n","Iter:    650,  Train Loss: 0.00062,  Train Acc: 100.00%,  Val Loss: 0.065,  Val Acc: 98.12%,  Time: 0:01:45 \n","Iter:    660,  Train Loss: 0.00074,  Train Acc: 100.00%,  Val Loss: 0.066,  Val Acc: 97.50%,  Time: 0:01:46 \n","Iter:    670,  Train Loss: 0.0018,  Train Acc: 100.00%,  Val Loss: 0.061,  Val Acc: 98.12%,  Time: 0:01:47 \n","Iter:    680,  Train Loss: 0.002,  Train Acc: 100.00%,  Val Loss: 0.058,  Val Acc: 98.12%,  Time: 0:01:49 \n","Iter:    690,  Train Loss: 0.00072,  Train Acc: 100.00%,  Val Loss: 0.058,  Val Acc: 98.12%,  Time: 0:01:50 \n","Epoch [15/25]\n","Iter:    700,  Train Loss: 0.00055,  Train Acc: 100.00%,  Val Loss: 0.061,  Val Acc: 98.12%,  Time: 0:01:51 \n","Iter:    710,  Train Loss: 0.00064,  Train Acc: 100.00%,  Val Loss: 0.063,  Val Acc: 98.75%,  Time: 0:01:52 \n","Iter:    720,  Train Loss: 0.00078,  Train Acc: 100.00%,  Val Loss: 0.061,  Val Acc: 98.75%,  Time: 0:01:54 \n","Iter:    730,  Train Loss: 0.0023,  Train Acc: 100.00%,  Val Loss: 0.061,  Val Acc: 98.75%,  Time: 0:01:55 \n","Iter:    740,  Train Loss: 0.00064,  Train Acc: 100.00%,  Val Loss: 0.063,  Val Acc: 98.75%,  Time: 0:01:56 \n","Epoch [16/25]\n","Iter:    750,  Train Loss: 0.0005,  Train Acc: 100.00%,  Val Loss: 0.066,  Val Acc: 98.75%,  Time: 0:01:57 \n","Iter:    760,  Train Loss: 0.00059,  Train Acc: 100.00%,  Val Loss: 0.067,  Val Acc: 98.75%,  Time: 0:01:58 \n","Iter:    770,  Train Loss: 0.00071,  Train Acc: 100.00%,  Val Loss: 0.067,  Val Acc: 98.75%,  Time: 0:02:00 \n","Iter:    780,  Train Loss: 0.0011,  Train Acc: 100.00%,  Val Loss: 0.067,  Val Acc: 98.75%,  Time: 0:02:01 \n","Iter:    790,  Train Loss: 0.00067,  Train Acc: 100.00%,  Val Loss: 0.067,  Val Acc: 98.75%,  Time: 0:02:02 \n","Epoch [17/25]\n","Iter:    800,  Train Loss: 0.00046,  Train Acc: 100.00%,  Val Loss:  0.07,  Val Acc: 98.75%,  Time: 0:02:03 \n","Iter:    810,  Train Loss: 0.00064,  Train Acc: 100.00%,  Val Loss: 0.071,  Val Acc: 98.75%,  Time: 0:02:05 \n","Iter:    820,  Train Loss: 0.00074,  Train Acc: 100.00%,  Val Loss: 0.065,  Val Acc: 98.75%,  Time: 0:02:06 \n","Iter:    830,  Train Loss: 0.00083,  Train Acc: 100.00%,  Val Loss: 0.063,  Val Acc: 98.75%,  Time: 0:02:07 \n","Iter:    840,  Train Loss: 0.00058,  Train Acc: 100.00%,  Val Loss: 0.062,  Val Acc: 98.75%,  Time: 0:02:08 \n","Epoch [18/25]\n","Iter:    850,  Train Loss: 0.00043,  Train Acc: 100.00%,  Val Loss: 0.064,  Val Acc: 98.75%,  Time: 0:02:09 \n","Iter:    860,  Train Loss: 0.00059,  Train Acc: 100.00%,  Val Loss: 0.065,  Val Acc: 98.75%,  Time: 0:02:11 \n","Iter:    870,  Train Loss: 0.00068,  Train Acc: 100.00%,  Val Loss: 0.062,  Val Acc: 98.75%,  Time: 0:02:12 \n","Iter:    880,  Train Loss: 0.00099,  Train Acc: 100.00%,  Val Loss:  0.06,  Val Acc: 98.75%,  Time: 0:02:13 \n","Iter:    890,  Train Loss: 0.00061,  Train Acc: 100.00%,  Val Loss:  0.06,  Val Acc: 98.75%,  Time: 0:02:14 \n","Epoch [19/25]\n","Iter:    900,  Train Loss: 0.00041,  Train Acc: 100.00%,  Val Loss:  0.06,  Val Acc: 98.75%,  Time: 0:02:15 \n","Iter:    910,  Train Loss: 0.00046,  Train Acc: 100.00%,  Val Loss:  0.06,  Val Acc: 98.75%,  Time: 0:02:17 \n","Iter:    920,  Train Loss: 0.00064,  Train Acc: 100.00%,  Val Loss: 0.062,  Val Acc: 98.75%,  Time: 0:02:18 \n","Iter:    930,  Train Loss: 0.00077,  Train Acc: 100.00%,  Val Loss: 0.062,  Val Acc: 98.75%,  Time: 0:02:19 \n","Iter:    940,  Train Loss: 0.00048,  Train Acc: 100.00%,  Val Loss: 0.062,  Val Acc: 98.75%,  Time: 0:02:20 \n","Epoch [20/25]\n","Iter:    950,  Train Loss: 0.00039,  Train Acc: 100.00%,  Val Loss: 0.066,  Val Acc: 98.75%,  Time: 0:02:21 \n","Iter:    960,  Train Loss: 0.00049,  Train Acc: 100.00%,  Val Loss: 0.067,  Val Acc: 98.75%,  Time: 0:02:23 \n","Iter:    970,  Train Loss: 0.00063,  Train Acc: 100.00%,  Val Loss: 0.064,  Val Acc: 98.75%,  Time: 0:02:24 \n","Iter:    980,  Train Loss: 0.0012,  Train Acc: 100.00%,  Val Loss: 0.062,  Val Acc: 98.75%,  Time: 0:02:25 \n","Iter:    990,  Train Loss: 0.00046,  Train Acc: 100.00%,  Val Loss: 0.062,  Val Acc: 98.75%,  Time: 0:02:26 \n","Epoch [21/25]\n","Iter:   1000,  Train Loss: 0.00037,  Train Acc: 100.00%,  Val Loss: 0.065,  Val Acc: 98.75%,  Time: 0:02:28 \n","Iter:   1010,  Train Loss: 0.00049,  Train Acc: 100.00%,  Val Loss: 0.065,  Val Acc: 98.75%,  Time: 0:02:29 \n","Iter:   1020,  Train Loss: 0.00055,  Train Acc: 100.00%,  Val Loss: 0.057,  Val Acc: 98.75%,  Time: 0:02:30 \n","Iter:   1030,  Train Loss: 0.00064,  Train Acc: 100.00%,  Val Loss: 0.056,  Val Acc: 98.75%,  Time: 0:02:31 \n","Iter:   1040,  Train Loss: 0.00046,  Train Acc: 100.00%,  Val Loss: 0.055,  Val Acc: 98.75%,  Time: 0:02:32 \n","Epoch [22/25]\n","Iter:   1050,  Train Loss: 0.00036,  Train Acc: 100.00%,  Val Loss: 0.051,  Val Acc: 98.75%,  Time: 0:02:34 \n","Iter:   1060,  Train Loss: 0.00045,  Train Acc: 100.00%,  Val Loss: 0.049,  Val Acc: 98.12%,  Time: 0:02:35 \n","Iter:   1070,  Train Loss: 0.00058,  Train Acc: 100.00%,  Val Loss: 0.048,  Val Acc: 98.12%,  Time: 0:02:36 \n","Iter:   1080,  Train Loss: 0.002,  Train Acc: 100.00%,  Val Loss: 0.047,  Val Acc: 98.12%,  Time: 0:02:37 \n","Iter:   1090,  Train Loss: 0.00045,  Train Acc: 100.00%,  Val Loss: 0.048,  Val Acc: 98.12%,  Time: 0:02:39 \n","Epoch [23/25]\n","Iter:   1100,  Train Loss: 0.00035,  Train Acc: 100.00%,  Val Loss: 0.048,  Val Acc: 98.12%,  Time: 0:02:40 \n","Iter:   1110,  Train Loss: 0.00045,  Train Acc: 100.00%,  Val Loss: 0.049,  Val Acc: 98.12%,  Time: 0:02:41 \n","Iter:   1120,  Train Loss: 0.00071,  Train Acc: 100.00%,  Val Loss: 0.048,  Val Acc: 98.12%,  Time: 0:02:42 \n","Iter:   1130,  Train Loss: 0.00082,  Train Acc: 100.00%,  Val Loss: 0.048,  Val Acc: 98.12%,  Time: 0:02:44 \n","Iter:   1140,  Train Loss: 0.00046,  Train Acc: 100.00%,  Val Loss: 0.048,  Val Acc: 98.12%,  Time: 0:02:45 \n","Epoch [24/25]\n","Iter:   1150,  Train Loss: 0.00035,  Train Acc: 100.00%,  Val Loss: 0.048,  Val Acc: 98.12%,  Time: 0:02:46 \n","Iter:   1160,  Train Loss: 0.00044,  Train Acc: 100.00%,  Val Loss: 0.048,  Val Acc: 98.12%,  Time: 0:02:47 \n","Iter:   1170,  Train Loss: 0.00051,  Train Acc: 100.00%,  Val Loss: 0.048,  Val Acc: 98.75%,  Time: 0:02:48 \n","Iter:   1180,  Train Loss: 0.0017,  Train Acc: 100.00%,  Val Loss: 0.048,  Val Acc: 98.75%,  Time: 0:02:50 \n","Iter:   1190,  Train Loss: 0.00044,  Train Acc: 100.00%,  Val Loss: 0.049,  Val Acc: 98.75%,  Time: 0:02:51 \n","Epoch [25/25]\n","Iter:   1200,  Train Loss: 0.00034,  Train Acc: 100.00%,  Val Loss: 0.049,  Val Acc: 98.75%,  Time: 0:02:52 \n","Iter:   1210,  Train Loss: 0.00043,  Train Acc: 100.00%,  Val Loss: 0.049,  Val Acc: 98.75%,  Time: 0:02:54 \n","Iter:   1220,  Train Loss: 0.00054,  Train Acc: 100.00%,  Val Loss: 0.049,  Val Acc: 98.75%,  Time: 0:02:55 \n","Iter:   1230,  Train Loss: 0.00091,  Train Acc: 100.00%,  Val Loss: 0.049,  Val Acc: 98.75%,  Time: 0:02:56 \n","Iter:   1240,  Train Loss: 0.00049,  Train Acc: 100.00%,  Val Loss: 0.049,  Val Acc: 98.75%,  Time: 0:02:57 \n","Test Loss:  0.24,  Test Acc: 94.39%\n","Precision, Recall and F1-Score...\n","              precision    recall  f1-score   support\n","\n","     med_use     0.8500    0.8947    0.8718        19\n","     med_con     0.9355    0.9062    0.9206        32\n","     med_sym     0.9615    0.9615    0.9615        26\n","     sym_med     1.0000    1.0000    1.0000        30\n","\n","    accuracy                         0.9439       107\n","   macro avg     0.9368    0.9406    0.9385       107\n","weighted avg     0.9447    0.9439    0.9442       107\n","\n","Confusion Matrix...\n","[[17  2  0  0]\n"," [ 2 29  1  0]\n"," [ 1  0 25  0]\n"," [ 0  0  0 30]]\n","Time usage: 0:00:00\n"]}]},{"cell_type":"code","source":["torch.save(model,'/content/drive/MyDrive/Bert-Chinese-Text-Classification-Pytorch-master/THUCNews/saved_dict/model')"],"metadata":{"id":"v855q4lRNhMu","executionInfo":{"status":"ok","timestamp":1648041533082,"user_tz":-480,"elapsed":8691,"user":{"displayName":"Yuxin Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15214000089252266369"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["import json"],"metadata":{"id":"2OXOLU5EYfTJ","executionInfo":{"status":"ok","timestamp":1648041535808,"user_tz":-480,"elapsed":2,"user":{"displayName":"Yuxin Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15214000089252266369"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["train_=[]\n","for i in train_log:\n","  train_.append(i.item())\n","\n","dev_=[]\n","for i in dev_log:\n","  dev_.append(i.item())"],"metadata":{"id":"Cla7EureYr4c","executionInfo":{"status":"ok","timestamp":1648041538168,"user_tz":-480,"elapsed":2,"user":{"displayName":"Yuxin Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15214000089252266369"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["filename='/content/drive/MyDrive/Bert-Chinese-Text-Classification-Pytorch-master/THUCNews/saved_dict/train_log.json'\n","with open(filename,'w',encoding='utf-8') as file_obj:\n","    json.dump(train_,file_obj,ensure_ascii=False,indent = 4)\n","\n","filename='/content/drive/MyDrive/Bert-Chinese-Text-Classification-Pytorch-master/THUCNews/saved_dict/dev_log.json'\n","with open(filename,'w',encoding='utf-8') as file_obj:\n","    json.dump(dev_,file_obj,ensure_ascii=False,indent = 4)"],"metadata":{"id":"f5ssFdTYM9FZ","executionInfo":{"status":"ok","timestamp":1648041541189,"user_tz":-480,"elapsed":722,"user":{"displayName":"Yuxin Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15214000089252266369"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"34mLsPdO9deE"},"execution_count":null,"outputs":[]}]}